# lab_4

Лабораторная работа 4

Цель настоящей работы состоит в том, чтобы построить архитектур  рекуррентных нейронных сетей, которые позволяют решить практическую задачу с высокими показателями качества.

Задачи

Выполнение практической работы предполагает решение следующих задач:

1. Разработка нескольких архитектур рекуррентных  нейронных сетей.

2. Обучение разработанных глубоких моделей.

3. Тестирование обученных глубоких моделей.

4. Сравнение полученных результатов с результатами 3 лабораторной работы.

5. Публикация разработанных программ/скриптов в личном репозитории на GitHub. (по желанию)

6. Подготовка отчета, содержащего минимальный объем информации по каждому этапу выполнения работы.

Код [ссылка](Лаб4.ipynb)

Отчет [ссылка]()

Для работы Было использовано подмножество набора данных Food-101. (Bossard, Lukas, Matthieu Guillaumin и Luc Van Gool. "Food-101 – Mining Discriminative Components with Random Forests") https://www.kaggle.com/datasets/carlosrunner/pizza-not-pizza Изображения находятся в папке "img" в двух папках, "pizza" и "not_pizza", в каждой папке 983 файла с изображениями.
![1](1.png)

В ходе работы было создано несколько моделей:

1. Создание модели с рекуррентной архитектурой (LSTM)

![2](2.png)

Точность на валидационной выборке: 66.72%

2. Создаём модель RNN

![3](3.png)

Анализ работы модели:

![4](4.png)

Выводы:

Точность (Accuracy): На графике точности синяя линия (обучающая выборка) стабильно растёт и достигает высоких значений (например, 0.85–0.95), это говорит о том, что нейросеть хорошо обучается на предоставленных данных. Однако, если оранжевая линия (валидационная выборка) значительно ниже (например, 0.6–0.75) или не растёт после первых эпох, это указывает на переобучение, и модель плохо обобщает на новые данные. Для RNN в задаче классификации изображений ожидаемая точность может быть ниже, чем у CNN. На сложных датасетах (например, CIFAR-10) типичная точность без доработок составляет 60–80%, на простых (например, MNIST) — до 95%. Если валидационная точность ниже 0.7, это низкий результат, требующий улучшений.

Потери (Loss): На графике потерь синяя линия (обучающая выборка) падает и стабилизируется на низком уровне (например, <0.3), это подтверждает успешное обучение. Если оранжевая линия (валидационная выборка) выше (например, >0.5) или начинает расти после нескольких эпох, это снова указывает на переобучение — модель теряет способность обобщать. В идеале обе линии должны быть близки и снижаться (например, обучающие потери 0.2, валидационные 0.25). Если разрыв между линиями велик, это негативно влияет на оценку работы модели.

3. Добавим сверточные слои:

![5](5.png)

Анализ работы модели:
![6](6.png)

Тест подтверждает, что модель не обучается: точность минимально изменяется и находится близко к уровню случайного угадывания (0.666 ≈ 2/3, что может соответствовать задаче на 3 класса, если случайное угадывание для 3 классов равно 1/3, а модель показывает чуть лучший результат). Потери стабилизировались слишком рано, а "плоские" графики указывают на отсутствие прогресса в обучении. Вывод: Модель неэффективна в текущей конфигурации. Результаты близки к случайным, что говорит о фундаментальных проблемах либо в архитектуре модели, либо в данных, либо в настройках обучения.

4. Попробуем убрать LSTM-слой и использовать чистую CNN-архитектуру:

